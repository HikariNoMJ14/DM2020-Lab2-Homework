{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import functools\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id  = pd.read_csv('./data/data_identification.csv')\n",
    "emo = pd.read_csv('./data/emotion.csv')\n",
    "\n",
    "tweets_str = open('./data/tweets_DM.json').read()\n",
    "tweets_str = \"[\" + tweets_str.replace(\"}\\n{\", \"}\\n,{\") + \"]\"\n",
    "tweets = json.loads(tweets_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(tweets[:100000])\n",
    "source = pd.DataFrame(list(tweet_df._source.apply(lambda x: x['tweet']).values))\n",
    "tweet_df = pd.concat([tweet_df, source], axis=1).drop(['_source','_type','_index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #freepress around the world. What a &lt;LH&gt; &lt;LH&gt; #TrumpLegacy.  #CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse &lt;LH&gt; &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens &lt;LH&gt; &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>70</td>\n",
       "      <td>2016-02-10 13:23:11</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2dbdcd</td>\n",
       "      <td>@HiltonEtwallSNT @DerbyshireFRS Will this nightmare never end &lt;LH&gt; councillor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>505</td>\n",
       "      <td>2017-03-09 19:17:26</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c68cb</td>\n",
       "      <td>Binge watched @netflix's @friendsfcollege It was so hilarious.I didn't want it to end.Can't believe pretty much every critic hated it.#loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>599</td>\n",
       "      <td>2015-09-10 23:27:16</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2f53c6</td>\n",
       "      <td>how did I cope all day in in work yesterday with less then 3 hours sleep &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>505</td>\n",
       "      <td>2016-02-27 03:26:45</td>\n",
       "      <td>[Tlou]</td>\n",
       "      <td>0x2485ba</td>\n",
       "      <td>#Tlou x2 +100% rises, 3.5p - 10p+, now 6.2p - 14.5p. &lt;LH&gt; performance from this share.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>470</td>\n",
       "      <td>2015-09-20 03:55:48</td>\n",
       "      <td>[Animatics, animation, art]</td>\n",
       "      <td>0x20e935</td>\n",
       "      <td>Currently working on #Animatics for New #animation project! &lt;LH&gt; #art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _score           _crawldate                       hashtags  tweet_id                                                                                                                                          text\n",
       "0         391  2015-05-23 11:42:47                     [Snapchat]  0x376b20                                                             People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's <LH>\n",
       "1         433  2016-01-28 04:52:09  [freepress, TrumpLegacy, CNN]  0x2d5350                                @brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN\n",
       "2         232  2017-12-25 04:39:20                   [bibleverse]  0x28b412         Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>\n",
       "3         376  2016-01-24 23:53:05                             []  0x1cd5b0                                                                                                           Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>\n",
       "4         989  2016-01-08 17:18:59                             []  0x2de201       \"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>\n",
       "...       ...                  ...                            ...       ...                                                                                                                                           ...\n",
       "99995      70  2016-02-10 13:23:11                             []  0x2dbdcd                                                                 @HiltonEtwallSNT @DerbyshireFRS Will this nightmare never end <LH> councillor\n",
       "99996     505  2017-03-09 19:17:26                             []  0x2c68cb  Binge watched @netflix's @friendsfcollege It was so hilarious.I didn't want it to end.Can't believe pretty much every critic hated it.#loved\n",
       "99997     599  2015-09-10 23:27:16                             []  0x2f53c6                                                                 how did I cope all day in in work yesterday with less then 3 hours sleep <LH>\n",
       "99998     505  2016-02-27 03:26:45                         [Tlou]  0x2485ba                                                        #Tlou x2 +100% rises, 3.5p - 10p+, now 6.2p - 14.5p. <LH> performance from this share.\n",
       "99999     470  2015-09-20 03:55:48    [Animatics, animation, art]  0x20e935                                                                         Currently working on #Animatics for New #animation project! <LH> #art\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sns.distplot(tweet_df._score % 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.merge(data_id, left_on='tweet_id', right_on='tweet_id')\n",
    "tweet_df = tweet_df.merge(emo, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.text = tweet_df.text.str.replace('<LH>', '')\n",
    "tweet_df.text = tweet_df.text.apply(emoji.get_emoji_regexp().split).apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove numbers\n",
    "    text_nonum = re.sub(r'\\d+', '', text)\n",
    "    # remove punctuations and convert characters to lower case\n",
    "    text_nopunct = \"\".join([char.lower() for char in text_nonum if char not in string.punctuation]) \n",
    "    # substitute multiple whitespace with single whitespace\n",
    "    # Also, removes leading and trailing whitespaces\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
    "    return text_no_doublespace\n",
    "\n",
    "tweet_df.text = tweet_df.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# hashtag_threshold = 200\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# add_tag = np.vectorize(lambda x: f\"hashtag_{x}\")\n",
    "# hashtags = pd.DataFrame(mlb.fit_transform(tweet_df.hashtags), columns=add_tag(mlb.classes_))\n",
    "# hashtag_freq = hashtags.sum(axis=0).sort_values(ascending=False)\n",
    "# hashtags = hashtags.filter(hashtag_freq.iloc[:hashtag_threshold].index)\n",
    "\n",
    "# tweet_df = pd.concat([tweet_df, hashtags], axis=1).drop('hashtags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tweet_df[tweet_df.identification == 'train'].drop('identification', axis=1)\n",
    "test_df = tweet_df[tweet_df.identification == 'test'].drop(['identification', 'emotion'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78187, 6)\n",
      "(21813, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>people who post add me on snapchat must be dehydrated cuz man thats</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas as we see trump is dangerous to freepress around the world what a trumplegacy cnn</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>now issa is stalking tasha ðŸ˜‚ ðŸ˜‚ ðŸ˜‚</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>2015-06-11 04:44:05</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>riskshow thekevinallison thx for the best time tonight what stories heartbreakingly authentic laughoutloud good</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1021</td>\n",
       "      <td>2015-08-18 02:30:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>still waiting on those supplies liscus</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score           _crawldate                       hashtags  tweet_id                                                                                                             text       emotion\n",
       "0     391  2015-05-23 11:42:47                     [Snapchat]  0x376b20                                              people who post add me on snapchat must be dehydrated cuz man thats  anticipation\n",
       "1     433  2016-01-28 04:52:09  [freepress, TrumpLegacy, CNN]  0x2d5350                     brianklaas as we see trump is dangerous to freepress around the world what a trumplegacy cnn       sadness\n",
       "3     376  2016-01-24 23:53:05                             []  0x1cd5b0                                                                                 now issa is stalking tasha ðŸ˜‚ ðŸ˜‚ ðŸ˜‚          fear\n",
       "5     120  2015-06-11 04:44:05      [authentic, LaughOutLoud]  0x1d755c  riskshow thekevinallison thx for the best time tonight what stories heartbreakingly authentic laughoutloud good           joy\n",
       "6    1021  2015-08-18 02:30:07                             []  0x2c91a8                                                                           still waiting on those supplies liscus  anticipation"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                        people who post add me on snapchat must be dehydrated cuz man thats\n",
       "1                                               brianklaas as we see trump is dangerous to freepress around the world what a trumplegacy cnn\n",
       "2                               confident of your obedience i write to you knowing that you will do even more than i ask philemon bibleverse\n",
       "3                                                                                                           now issa is stalking tasha ðŸ˜‚ ðŸ˜‚ ðŸ˜‚\n",
       "4                     trust is not the same as faith a friend is someone you trust putting faith in anyone is a mistake christopher hitchens\n",
       "                                                                        ...                                                                 \n",
       "99995                                                                 hiltonetwallsnt derbyshirefrs will this nightmare never end councillor\n",
       "99996    binge watched netflixs friendsfcollege it was so hilariousi didnt want it to endcant believe pretty much every critic hated itloved\n",
       "99997                                                                 how did i cope all day in in work yesterday with less then hours sleep\n",
       "99998                                                                                   tlou x rises p p now p p performance from this share\n",
       "99999                                                                           currently working on animatics for new animation project art\n",
       "Name: text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/PycharmProjects/data_mining/venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "tweet_tokenizer = nltk.tokenize.casual.TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "# build analyzers (td-idf)\n",
    "TDIDF_1000 = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "#     ngram_range=(1,3),\n",
    "    tokenizer=tweet_tokenizer.tokenize, \n",
    "    stop_words='english', \n",
    "    lowercase=True,\n",
    "    strip_accents='unicode'\n",
    ") \n",
    "\n",
    "# apply analyzer to training data\n",
    "TDIDF_1000 = TDIDF_1000.fit(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (58640, 10000)\n",
      "y_train.shape:  (58640,)\n",
      "X_test.shape:  (19547, 10000)\n",
      "y_test.shape:  (19547,)\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(TDIDF_1000.transform(train_df['text']), train_df['emotion'], shuffle=False)\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def train_and_eval(model, X_tr, X_te, y_tr, y_te, **params):\n",
    "    model = model(\n",
    "        **params, \n",
    "        class_weight='balanced')\\\n",
    "    .fit(\n",
    "        X=X_train.toarray(), \n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    y_train_pred = model.predict(X_train.toarray())\n",
    "    y_test_pred = model.predict(X_test.toarray())\n",
    "\n",
    "    acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "    acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    print(model)\n",
    "    print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "    print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "    print('----------------------------')\n",
    "    print(classification_report(y_true=y_test, y_pred=y_test_pred))\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_eval(LogisticRegression, X_train, X_test, y_train, y_test)\n",
    "# train_and_eval(MLPClassifier, X_train, X_test, y_train, y_test)\n",
    "model = train_and_eval(model=DecisionTreeClassifier, X_tr=X_train, X_te=X_test, y_tr=y_train, y_te=y_test)\n",
    "# train_and_eval(KNeighborsClassifier, X_train, X_test, y_train, y_test)\n",
    "# train_and_eval(SVC, X_train, X_test, y_train, y_test)\n",
    "# train_and_eval(GaussianProcessClassifier, X_train, X_test, y_train, y_test)\n",
    "# model = train_and_eval(model=RandomForestClassifier, X_tr=X_train, X_te=X_test, y_tr=y_train, y_te=y_test)\n",
    "# train_and_eval(AdaBoostClassifier, X_train, X_test, y_train, y_test)\n",
    "# train_and_eval(GaussianNB, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf = pd.DataFrame(data=X_train.toarray(), columns=TDIDF_1000.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tdidf.iloc[10]\n",
    "s[s != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4a92a2ade133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s[s != 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tdidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a3b3555cf057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tdidf' is not defined"
     ]
    }
   ],
   "source": [
    "tdidf.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1802570211530874"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()[10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.text.str.replace('<LH>', '').iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>people who post add me on snapchat must be dehydrated cuz man thats</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas as we see trump is dangerous to freepress around the world what a trumplegacy cnn</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>now issa is stalking tasha ðŸ˜‚ ðŸ˜‚ ðŸ˜‚</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>2015-06-11 04:44:05</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>riskshow thekevinallison thx for the best time tonight what stories heartbreakingly authentic laughoutloud good</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1021</td>\n",
       "      <td>2015-08-18 02:30:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>still waiting on those supplies liscus</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score           _crawldate                       hashtags  tweet_id                                                                                                             text       emotion\n",
       "0     391  2015-05-23 11:42:47                     [Snapchat]  0x376b20                                              people who post add me on snapchat must be dehydrated cuz man thats  anticipation\n",
       "1     433  2016-01-28 04:52:09  [freepress, TrumpLegacy, CNN]  0x2d5350                     brianklaas as we see trump is dangerous to freepress around the world what a trumplegacy cnn       sadness\n",
       "3     376  2016-01-24 23:53:05                             []  0x1cd5b0                                                                                 now issa is stalking tasha ðŸ˜‚ ðŸ˜‚ ðŸ˜‚          fear\n",
       "5     120  2015-06-11 04:44:05      [authentic, LaughOutLoud]  0x1d755c  riskshow thekevinallison thx for the best time tonight what stories heartbreakingly authentic laughoutloud good           joy\n",
       "6    1021  2015-08-18 02:30:07                             []  0x2c91a8                                                                           still waiting on those supplies liscus  anticipation"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = np.array(TDIDF_1000.get_feature_names())\n",
    "tfidf_sorting = np.argsort(X_train.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 100\n",
    "top_n = feature_array[tfidf_sorting][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happening', 'friend', '\\U000e0067', 'gal', 'gambling', 'gallon',\n",
       "       'gallery', 'galgadot', 'galaxy', 'galatians', 'gains', 'gameday',\n",
       "       'gaining', 'gained', 'gain', 'gaia', 'gaga', 'gag', 'ga', 'game',\n",
       "       'gamedev', 'fyi', 'gap', 'garybarlow', 'gary', 'garlic', 'gardens',\n",
       "       'garden', 'garbage', 'garage', 'gang', 'gameofthones', 'ganesh',\n",
       "       'gandhi', 'gaming', 'games', 'gamer', 'gameofthronesfinale',\n",
       "       'gameofthrones', 'g', 'futures', 'fuzzy', 'fucking', 'fulfilling',\n",
       "       'fulfilled', 'fulfill', 'fulfil', 'fuk', 'fuel', 'fucks', 'fuckin',\n",
       "       'gas', 'fucker', 'fucken', 'fucked', 'fuck', 'fu', 'ft', 'fsu',\n",
       "       'fulfillment', 'fullest', 'fullness', 'fully', 'future', 'futile',\n",
       "       'fuss', 'fury', 'furniture', 'fur', 'funny', 'funniest', 'funk',\n",
       "       'funds', 'funding', 'funder', 'fund', 'function', 'fun', 'garyvee',\n",
       "       'gate', 'fry', 'georgiadirtroad', 'getspectrum', 'gets', 'getout',\n",
       "       'getaway', 'gesture', 'germany', 'german', 'georgia', 'gentle',\n",
       "       'georgetakei', 'georgemichael', 'george', 'genuinely', 'genuine',\n",
       "       'gentleness', 'gentlemen', 'gettin', 'getting'], dtype='<U28')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
